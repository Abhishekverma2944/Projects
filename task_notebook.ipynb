{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6591a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "from langchain import HuggingFacePipeline, PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cddd51",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc15668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 5068446 characters\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"alt.atheism.txt\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(f\"Dataset length: {len(raw_text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98818f",
   "metadata": {},
   "source": [
    "Split into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8742a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 6879\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.create_documents([raw_text])\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03436410",
   "metadata": {},
   "source": [
    "Use a free sentence-transformers embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ee88fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_4516\\2945161494.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e074a",
   "metadata": {},
   "source": [
    " Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef84e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved docs: 4\n",
      "KS> When he asked for this book, the well educated American book store\n",
      "KS> assistants in most placed asked him to check out the thriller section,\n",
      "KS> or then they said that his book has not been published yet, but they\n",
      "KS> should receive the book soon. In some places the assistants bluntly\n",
      "KS> said that they don't know of such an author, or that he is not \n",
      "KS> a well known living author, so they don't keep copies of his books.\n",
      "\n",
      "KS> Such is the life and times of America, 200+ years after the revo\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "query = \"What does this dataset say about Books ?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(\"Retrieved docs:\", len(retrieved_docs))\n",
    "print(retrieved_docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11367c",
   "metadata": {},
   "source": [
    "LLM & Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3fbfa",
   "metadata": {},
   "source": [
    "Run Retrieval + Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb7a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-large\",  # or flan-t5-base\n",
    "    # max_new_tokens=256  # <-- controls how many tokens to generate\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=qa_pipeline)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a helpful assistant.\n",
    "      Answer ONLY from the provided dataset context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      Context:\n",
    "      {context}\n",
    "\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=['context', 'question']\n",
    ")\n",
    "\n",
    "# Test\n",
    "question = \"What is the main theme discussed in these documents?\"\n",
    "# question = \"tell about United Kingdom from the document?\"\n",
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "final_prompt = prompt.format(context=context_text, question=question)\n",
    "answer = llm.invoke(final_prompt)\n",
    "\n",
    "print(\"Answer:\\n\",answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91384db9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5235dc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
